import nltk
from nltk.tokenize import sent_tokenize, word_tokenize, PunktSentenceTokenizer
from nltk.corpus import webtext
from nltk.stem.porter import PorterStemmer
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Open and read the text file
with open('kindle.txt', encoding='ISO-8859-2') as f:
    text = f.read()

# Tokenize sentences
sent_tokenizer = PunktSentenceTokenizer(text)
sents = sent_tokenizer.tokenize(text)

# Print tokenized words and sentences
print(word_tokenize(text))
print(sent_tokenize(text))

# Stem words
porter_stemmer = PorterStemmer()
nltk_tokens = nltk.word_tokenize(text)

for w in nltk_tokens:
    print("Actual: %s Stem: %s" % (w, porter_stemmer.stem(w)))

# Lemmatize words
wordnet_lemmatizer = WordNetLemmatizer()
nltk_tokens = nltk.word_tokenize(text)

for w in nltk_tokens:
    print("Actual: %s Lemma: %s" % (w, wordnet_lemmatizer.lemmatize(w)))

# Part-of-speech tagging
text_tokens = nltk.word_tokenize(text)
print(nltk.pos_tag(text_tokens))

# Sentiment analysis
sid = SentimentIntensityAnalyzer()

with open('kindle.txt', encoding='ISO-8859-2') as f:
    for line in f.read().split('\n'):
        print(line)
        scores = sid.polarity_scores(line)
        for key in sorted(scores):
            print('{0}: {1}, '.format(key, scores[key]), end='')
        print()